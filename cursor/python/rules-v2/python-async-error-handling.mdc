---
description: Правила обработки ошибок в асинхронном коде Python
globs: "*.py"
alwaysApply: false
related: ["python-error-handling-principles.mdc", "python-web-error-handling.mdc"]
priority: 7
---
# Обработка ошибок в асинхронном коде Python

Рекомендации по обработке ошибок и исключений в асинхронном коде Python. Правильная обработка ошибок в асинхронном коде имеет свои особенности и требует специальных подходов.

---

## Основные принципы обработки ошибок в асинхронном коде

1. **Явная обработка**: Всегда явно обрабатывайте исключения в асинхронных функциях.
2. **Распространение исключений**: Учитывайте, что необработанные исключения в корутинах могут быть потеряны.
3. **Отмена задач**: Правильно обрабатывайте отмену задач и связанные с ней исключения.
4. **Таймауты**: Всегда устанавливайте таймауты для асинхронных операций.
5. **Логирование**: Логируйте исключения в асинхронном коде с достаточным контекстом.
6. **Централизованная обработка**: Используйте централизованные механизмы обработки ошибок.

## Обработка исключений в asyncio

### Базовая обработка исключений

```python
import asyncio
import logging

logger = logging.getLogger(__name__)

async def fetch_data(url):
    """Асинхронная функция для получения данных."""
    try:
        # Асинхронный запрос
        response = await make_request(url)
        return response
    except aiohttp.ClientError as e:
        # Обработка ошибок клиента
        logger.error(f"Client error while fetching {url}: {e}")
        raise DataFetchError(f"Failed to fetch data from {url}") from e
    except asyncio.TimeoutError:
        # Обработка таймаута
        logger.error(f"Timeout while fetching {url}")
        raise DataFetchError(f"Timeout while fetching data from {url}")
    except Exception as e:
        # Обработка других ошибок
        logger.exception(f"Unexpected error while fetching {url}")
        raise DataFetchError(f"Unexpected error while fetching data from {url}") from e
```

### Обработка исключений при запуске задач

```python
import asyncio
import logging

logger = logging.getLogger(__name__)

async def process_items(items):
    """Обработка списка элементов с обработкой ошибок."""
    tasks = []
    results = []
    
    # Создание задач
    for item in items:
        task = asyncio.create_task(process_item(item))
        tasks.append(task)
    
    # Ожидание завершения всех задач
    for task in asyncio.as_completed(tasks):
        try:
            result = await task
            results.append(result)
        except Exception as e:
            logger.error(f"Error processing item: {e}")
            # Продолжаем выполнение, несмотря на ошибку
    
    return results

async def process_item(item):
    """Обработка одного элемента."""
    # Обработка элемента
    return await do_something_with_item(item)
```

### Обработка отмены задач

```python
import asyncio
import logging

logger = logging.getLogger(__name__)

async def process_with_timeout(coroutine, timeout=10):
    """Выполнение корутины с таймаутом и обработкой отмены."""
    try:
        # Запуск корутины с таймаутом
        return await asyncio.wait_for(coroutine, timeout=timeout)
    except asyncio.TimeoutError:
        logger.warning(f"Operation timed out after {timeout} seconds")
        raise TimeoutError(f"Operation timed out after {timeout} seconds")
    except asyncio.CancelledError:
        logger.info("Operation was cancelled")
        # Повторное возбуждение исключения для правильной отмены
        raise
    except Exception as e:
        logger.exception(f"Error during operation: {e}")
        raise

async def main():
    try:
        result = await process_with_timeout(fetch_data("https://example.com"))
        print(f"Result: {result}")
    except TimeoutError as e:
        print(f"Timeout: {e}")
    except Exception as e:
        print(f"Error: {e}")
```

### Обработка исключений в группах задач

```python
import asyncio
import logging

logger = logging.getLogger(__name__)

async def process_urls(urls):
    """Обработка списка URL с использованием TaskGroup."""
    results = {}
    errors = {}
    
    # Python 3.11+: использование TaskGroup
    async with asyncio.TaskGroup() as tg:
        # Создание задач
        for url in urls:
            tg.create_task(fetch_data(url), name=url)
    
    # Обработка результатов и ошибок
    for task in tg.tasks:
        url = task.get_name()
        if task.cancelled():
            errors[url] = "Task was cancelled"
        elif task.exception() is not None:
            errors[url] = str(task.exception())
        else:
            results[url] = task.result()
    
    return results, errors

# Для Python 3.10 и ниже
async def process_urls_legacy(urls):
    """Обработка списка URL с использованием gather и обработкой исключений."""
    tasks = [fetch_data(url) for url in urls]
    results = {}
    errors = {}
    
    # Запуск задач с return_exceptions=True
    responses = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Обработка результатов и ошибок
    for url, response in zip(urls, responses):
        if isinstance(response, Exception):
            errors[url] = str(response)
            logger.error(f"Error fetching {url}: {response}")
        else:
            results[url] = response
    
    return results, errors
```

### Использование контекстных менеджеров

```python
import asyncio
import aiohttp
import logging
from contextlib import asynccontextmanager

logger = logging.getLogger(__name__)

@asynccontextmanager
async def managed_session():
    """Асинхронный контекстный менеджер для сессии aiohttp."""
    session = aiohttp.ClientSession()
    try:
        yield session
    except Exception as e:
        logger.exception(f"Error during session: {e}")
        raise
    finally:
        await session.close()

async def fetch_urls(urls):
    """Получение данных с нескольких URL с использованием контекстного менеджера."""
    results = {}
    
    async with managed_session() as session:
        for url in urls:
            try:
                async with session.get(url, timeout=10) as response:
                    response.raise_for_status()
                    results[url] = await response.json()
            except aiohttp.ClientError as e:
                logger.error(f"Client error for {url}: {e}")
                results[url] = {"error": str(e)}
            except asyncio.TimeoutError:
                logger.error(f"Timeout for {url}")
                results[url] = {"error": "Request timed out"}
    
    return results
```

## Обработка ошибок в асинхронных веб-приложениях

### FastAPI

```python
from fastapi import FastAPI, HTTPException, Request, BackgroundTasks
from fastapi.responses import JSONResponse
import logging
import asyncio

app = FastAPI()
logger = logging.getLogger(__name__)

class AsyncOperationError(Exception):
    """Ошибка асинхронной операции."""
    def __init__(self, message, status_code=500):
        self.message = message
        self.status_code = status_code
        super().__init__(self.message)

@app.exception_handler(AsyncOperationError)
async def async_operation_exception_handler(request: Request, exc: AsyncOperationError):
    """Обработчик ошибок асинхронных операций."""
    return JSONResponse(
        status_code=exc.status_code,
        content={"status": "error", "message": exc.message}
    )

@app.get("/data/{item_id}")
async def get_data(item_id: str, background_tasks: BackgroundTasks):
    """Эндпоинт для получения данных с обработкой ошибок."""
    try:
        # Асинхронная операция с таймаутом
        result = await asyncio.wait_for(fetch_item_data(item_id), timeout=5.0)
        
        # Фоновая задача для обработки результата
        background_tasks.add_task(process_result, result)
        
        return {"status": "success", "data": result}
    except asyncio.TimeoutError:
        logger.error(f"Timeout while fetching data for item {item_id}")
        raise AsyncOperationError(
            message=f"Operation timed out for item {item_id}",
            status_code=504
        )
    except ItemNotFoundError as e:
        logger.warning(f"Item not found: {e}")
        raise AsyncOperationError(
            message=str(e),
            status_code=404
        )
    except Exception as e:
        logger.exception(f"Unexpected error for item {item_id}: {e}")
        raise AsyncOperationError(
            message="An unexpected error occurred",
            status_code=500
        )

async def process_result(result):
    """Фоновая обработка результата с обработкой ошибок."""
    try:
        await do_processing(result)
    except Exception as e:
        logger.exception(f"Error processing result: {e}")
        # Сохранение информации об ошибке
        await save_error_info(result, str(e))
```

### aiohttp

```python
from aiohttp import web
import logging
import traceback

logger = logging.getLogger(__name__)

# Middleware для обработки исключений
@web.middleware
async def error_middleware(request, handler):
    """Middleware для обработки ошибок в aiohttp."""
    try:
        response = await handler(request)
        return response
    except web.HTTPException as ex:
        # Обработка HTTP-исключений
        return web.json_response(
            {"status": "error", "message": ex.reason},
            status=ex.status
        )
    except Exception as e:
        # Обработка неожиданных исключений
        logger.exception(f"Unhandled exception: {e}")
        return web.json_response(
            {
                "status": "error",
                "message": "Internal server error",
                "trace_id": request.get("trace_id", "unknown")
            },
            status=500
        )

# Обработчик с обработкой ошибок
async def get_user(request):
    """Обработчик для получения пользователя с обработкой ошибок."""
    try:
        user_id = request.match_info.get("user_id")
        
        # Асинхронная операция
        user = await get_user_from_db(user_id)
        
        if not user:
            raise web.HTTPNotFound(reason=f"User with ID {user_id} not found")
        
        return web.json_response(user)
    except DatabaseError as e:
        logger.error(f"Database error: {e}")
        raise web.HTTPServiceUnavailable(reason="Database error")

# Настройка приложения
app = web.Application(middlewares=[error_middleware])
app.add_routes([web.get("/users/{user_id}", get_user)])
```

## Лучшие практики

### 1. Используйте таймауты для всех асинхронных операций

```python
import asyncio
import aiohttp
import logging

logger = logging.getLogger(__name__)

async def fetch_with_timeout(url, timeout=10):
    """Получение данных с таймаутом."""
    try:
        async with aiohttp.ClientSession() as session:
            # Установка таймаута для всей операции
            async with session.get(url, timeout=aiohttp.ClientTimeout(total=timeout)) as response:
                response.raise_for_status()
                return await response.json()
    except asyncio.TimeoutError:
        logger.error(f"Request to {url} timed out after {timeout} seconds")
        raise TimeoutError(f"Request timed out after {timeout} seconds")
    except aiohttp.ClientError as e:
        logger.error(f"Client error for {url}: {e}")
        raise
```

### 2. Обрабатывайте отмену задач

```python
import asyncio
import logging

logger = logging.getLogger(__name__)

async def cancellable_operation():
    """Операция с обработкой отмены."""
    try:
        # Длительная операция
        for i in range(10):
            # Проверка отмены
            if asyncio.current_task().cancelled():
                logger.info("Task was cancelled, cleaning up...")
                # Очистка ресурсов
                break
            
            await asyncio.sleep(1)
            print(f"Step {i+1}/10")
        
        return "Operation completed"
    except asyncio.CancelledError:
        logger.info("Task was cancelled during execution")
        # Очистка ресурсов
        
        # Повторное возбуждение исключения для правильной отмены
        raise

async def main():
    # Создание задачи
    task = asyncio.create_task(cancellable_operation())
    
    # Ожидание 3 секунды
    await asyncio.sleep(3)
    
    # Отмена задачи
    task.cancel()
    
    try:
        # Ожидание завершения задачи
        await task
    except asyncio.CancelledError:
        print("Task was cancelled")
```

### 3. Используйте декораторы для обработки исключений

```python
import asyncio
import functools
import logging

logger = logging.getLogger(__name__)

def handle_async_exceptions(func):
    """Декоратор для обработки исключений в асинхронных функциях."""
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        try:
            return await func(*args, **kwargs)
        except asyncio.TimeoutError:
            logger.error(f"Timeout in {func.__name__}")
            raise TimeoutError(f"Operation {func.__name__} timed out")
        except asyncio.CancelledError:
            logger.info(f"Task {func.__name__} was cancelled")
            raise
        except Exception as e:
            logger.exception(f"Error in {func.__name__}: {e}")
            raise OperationError(f"Error in {func.__name__}: {e}") from e
    return wrapper

@handle_async_exceptions
async def fetch_data(url):
    """Получение данных с обработкой исключений."""
    async with aiohttp.ClientSession() as session:
        async with session.get(url, timeout=10) as response:
            response.raise_for_status()
            return await response.json()
```

### 4. Используйте asyncio.gather с return_exceptions

```python
import asyncio
import logging

logger = logging.getLogger(__name__)

async def process_items(items):
    """Обработка списка элементов с использованием gather."""
    # Создание корутин
    coroutines = [process_item(item) for item in items]
    
    # Запуск всех корутин с return_exceptions=True
    results = await asyncio.gather(*coroutines, return_exceptions=True)
    
    # Обработка результатов
    processed_results = []
    errors = []
    
    for item, result in zip(items, results):
        if isinstance(result, Exception):
            logger.error(f"Error processing item {item}: {result}")
            errors.append((item, result))
        else:
            processed_results.append(result)
    
    # Логирование общей статистики
    logger.info(f"Processed {len(processed_results)} items, {len(errors)} errors")
    
    return processed_results, errors
```

### 5. Используйте асинхронные контекстные менеджеры для ресурсов

```python
import asyncio
import aiohttp
import aiopg
import logging
from contextlib import asynccontextmanager

logger = logging.getLogger(__name__)

@asynccontextmanager
async def database_connection(dsn):
    """Асинхронный контекстный менеджер для подключения к базе данных."""
    pool = await aiopg.create_pool(dsn)
    try:
        yield pool
    except Exception as e:
        logger.exception(f"Database error: {e}")
        raise
    finally:
        pool.close()
        await pool.wait_closed()

@asynccontextmanager
async def http_session():
    """Асинхронный контекстный менеджер для HTTP-сессии."""
    session = aiohttp.ClientSession()
    try:
        yield session
    except Exception as e:
        logger.exception(f"HTTP session error: {e}")
        raise
    finally:
        await session.close()

async def process_data():
    """Обработка данных с использованием нескольких ресурсов."""
    async with database_connection("postgresql://user:pass@localhost/db") as db_pool:
        async with http_session() as session:
            # Использование обоих ресурсов
            async with db_pool.acquire() as conn:
                async with conn.cursor() as cur:
                    await cur.execute("SELECT * FROM items")
                    items = await cur.fetchall()
            
            # Отправка данных через HTTP
            for item in items:
                try:
                    async with session.post("https://example.com/api", json=item) as response:
                        response.raise_for_status()
                        print(f"Sent item {item[0]}")
                except Exception as e:
                    logger.error(f"Error sending item {item[0]}: {e}")
```

### 6. Обрабатывайте исключения в асинхронных генераторах

```python
import asyncio
import logging

logger = logging.getLogger(__name__)

async def fetch_items_batch(batch_size=10):
    """Асинхронный генератор для получения пакетов элементов."""
    offset = 0
    
    try:
        while True:
            try:
                # Получение пакета элементов
                items = await fetch_items(offset, batch_size)
                
                if not items:
                    break
                
                yield items
                offset += batch_size
            except DatabaseError as e:
                logger.error(f"Database error at offset {offset}: {e}")
                # Повторная попытка через 5 секунд
                await asyncio.sleep(5)
            except Exception as e:
                logger.exception(f"Unexpected error at offset {offset}: {e}")
                raise
    except asyncio.CancelledError:
        logger.info("Fetch operation was cancelled")
        # Очистка ресурсов
        raise
    finally:
        logger.info(f"Fetch operation completed, processed {offset} items")

async def process_items_stream():
    """Обработка потока элементов из асинхронного генератора."""
    try:
        async for batch in fetch_items_batch(batch_size=20):
            try:
                # Обработка пакета
                await process_batch(batch)
            except ProcessingError as e:
                logger.error(f"Error processing batch: {e}")
                # Продолжаем с следующим пакетом
    except Exception as e:
        logger.exception(f"Fatal error in item processing: {e}")
        raise
```

### 7. Используйте семафоры для ограничения параллельных задач

```python
import asyncio
import aiohttp
import logging

logger = logging.getLogger(__name__)

async def fetch_all_urls(urls, max_concurrent=10):
    """Получение данных с нескольких URL с ограничением параллельных запросов."""
    # Создание семафора
    semaphore = asyncio.Semaphore(max_concurrent)
    results = {}
    errors = {}
    
    async def fetch_with_semaphore(url):
        """Получение данных с использованием семафора."""
        async with semaphore:
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, timeout=10) as response:
                        response.raise_for_status()
                        return await response.json()
            except aiohttp.ClientError as e:
                logger.error(f"Client error for {url}: {e}")
                raise FetchError(f"Error fetching {url}: {e}")
            except asyncio.TimeoutError:
                logger.error(f"Timeout for {url}")
                raise FetchError(f"Timeout fetching {url}")
    
    # Создание задач
    tasks = [asyncio.create_task(fetch_with_semaphore(url)) for url in urls]
    
    # Ожидание завершения всех задач
    for url, task in zip(urls, asyncio.as_completed(tasks)):
        try:
            results[url] = await task
        except Exception as e:
            errors[url] = str(e)
    
    return results, errors
```

## Интеграция с другими правилами

- **Принципы обработки ошибок**: Основные принципы обработки ошибок описаны в @python-error-handling-principles.mdc
- **Обработка ошибок в веб-приложениях**: Рекомендации по обработке ошибок в веб-приложениях описаны в @python-web-error-handling.mdc 